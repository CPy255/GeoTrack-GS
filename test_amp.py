#!/usr/bin/env python3
"""
æµ‹è¯•æ··åˆç²¾åº¦è®­ç»ƒçš„ç®€å•éªŒè¯è„šæœ¬
"""

import torch
from torch.cuda.amp import autocast, GradScaler
import argparse

def test_amp_functionality():
    """æµ‹è¯•AMPåŸºæœ¬åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•AMPåŸºæœ¬åŠŸèƒ½...")
    
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œæ— æ³•æµ‹è¯•AMP")
        return False
    
    # åˆ›å»ºç®€å•çš„æµ‹è¯•æ•°æ®
    device = torch.device('cuda')
    x = torch.randn(100, 64, requires_grad=True, device=device)
    y = torch.randn(100, 64, device=device)
    
    # åˆ›å»ºç®€å•æ¨¡å‹
    model = torch.nn.Linear(64, 64).to(device)
    optimizer = torch.optim.Adam(model.parameters())
    scaler = GradScaler()
    
    # æµ‹è¯•FP16è®­ç»ƒ
    try:
        with autocast(dtype=torch.float16):
            output = model(x)
            loss = torch.nn.functional.mse_loss(output, y)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()
        
        print("âœ… AMPåŸºæœ¬åŠŸèƒ½æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ AMPåŸºæœ¬åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_amp_with_gaussian_ops():
    """æµ‹è¯•AMPä¸3D Gaussianç›¸å…³æ“ä½œçš„å…¼å®¹æ€§"""
    print("ğŸ§ª æµ‹è¯•AMPä¸3D Gaussianæ“ä½œçš„å…¼å®¹æ€§...")
    
    try:
        device = torch.device('cuda')
        
        # æ¨¡æ‹Ÿ3D Gaussianå‚æ•°
        xyz = torch.randn(1000, 3, device=device, requires_grad=True)
        scaling = torch.randn(1000, 3, device=device, requires_grad=True)
        rotation = torch.randn(1000, 4, device=device, requires_grad=True)
        features = torch.randn(1000, 48, device=device, requires_grad=True)  # SH coefficients
        
        optimizer = torch.optim.Adam([xyz, scaling, rotation, features])
        scaler = GradScaler()
        
        with autocast(dtype=torch.float16):
            # æ¨¡æ‹ŸæŸå¤±è®¡ç®—
            # 1. L1æŸå¤±
            rendered = torch.sigmoid(features[:, :3])  # ç®€åŒ–çš„é¢œè‰²
            gt = torch.rand_like(rendered)
            l1_loss = torch.abs(rendered - gt).mean()
            
            # 2. æ·±åº¦æŸå¤±æ¨¡æ‹Ÿ
            depth_pred = xyz[:, 2]  # ç®€åŒ–çš„æ·±åº¦
            depth_gt = torch.randn_like(depth_pred)
            # æ¨¡æ‹Ÿpearsonç›¸å…³ç³»æ•°è®¡ç®—
            depth_loss = 1 - torch.corrcoef(torch.stack([depth_pred, depth_gt]))[0, 1]
            
            # 3. å‡ ä½•æ­£åˆ™åŒ–æ¨¡æ‹Ÿ
            scaling_activated = torch.exp(scaling)
            reg_loss = torch.mean(scaling_activated.max(dim=1)[0] / (scaling_activated.min(dim=1)[0] + 1e-6))
            
            total_loss = l1_loss + 0.03 * depth_loss + 0.01 * reg_loss
        
        scaler.scale(total_loss).backward()
        scaler.step(optimizer)
        scaler.update()
        optimizer.zero_grad()
        
        print("âœ… AMPä¸3D Gaussianæ“ä½œå…¼å®¹æ€§æµ‹è¯•é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ AMPä¸3D Gaussianæ“ä½œå…¼å®¹æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    parser = argparse.ArgumentParser(description='æµ‹è¯•AMPåŠŸèƒ½')
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹æµ‹è¯•AMPå®ç°...")
    print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
    print(f"CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name()}")
    print("-" * 50)
    
    all_passed = True
    
    # åŸºæœ¬AMPæµ‹è¯•
    if not test_amp_functionality():
        all_passed = False
    
    # 3D Gaussianç›¸å…³æµ‹è¯•
    if not test_amp_with_gaussian_ops():
        all_passed = False
    
    print("-" * 50)
    if all_passed:
        print("ğŸ‰ æ‰€æœ‰AMPæµ‹è¯•é€šè¿‡ï¼æ‚¨çš„å®ç°åº”è¯¥å¯ä»¥æ­£å¸¸å·¥ä½œã€‚")
        print("ğŸ’¡ å»ºè®®ï¼šåœ¨å®é™…è®­ç»ƒä¸­ä½¿ç”¨ --mixed_precision å‚æ•°å¯ç”¨AMP")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥CUDAç¯å¢ƒå’ŒAMPæ”¯æŒ")
    
    return 0 if all_passed else 1

if __name__ == "__main__":
    exit_code = main()
    exit(exit_code)