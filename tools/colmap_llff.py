import os
import sys
import shutil
import sqlite3
import numpy as np
import argparse

# --- å…¨å±€å¸¸é‡å’Œç‰ˆæœ¬æ£€æŸ¥ ---
IS_PYTHON3 = sys.version_info[0] >= 3
MAX_IMAGE_ID = 2**31 - 1

# --- è¾…åŠ©å‡½æ•° ---

def run_command(cmd, exit_on_fail=True):
    """
    æ‰§è¡Œä¸€ä¸ªshellå‘½ä»¤ï¼Œå¹¶æ£€æŸ¥å…¶è¿”å›å€¼ã€‚
    å¦‚æœå‘½ä»¤å¤±è´¥ï¼Œå¯ä»¥é€‰æ‹©é€€å‡ºè„šæœ¬ã€‚
    """
    print(f"ğŸš€ [RUNNING]: {cmd}")
    return_code = os.system(cmd)
    if return_code != 0:
        print(f"âŒ [ERROR]: Command failed with exit code {return_code}")
        print(f"  > Failed command: {cmd}")
        if exit_on_fail:
            sys.exit(1)
    return return_code

def array_to_blob(array):
    """å°†Numpyæ•°ç»„è½¬æ¢ä¸ºSQLite BLOB"""
    if IS_PYTHON3:
        return array.tobytes()
    else:
        # np.getbuffer is deprecated in Python 3
        return np.getbuffer(array)

def blob_to_array(blob, dtype, shape=(-1,)):
    """å°†SQLite BLOBè½¬æ¢å›Numpyæ•°ç»„"""
    if IS_PYTHON3:
        return np.frombuffer(blob, dtype=dtype).reshape(*shape)
    else:
        return np.frombuffer(blob, dtype=dtype).reshape(*shape)

def round_python3(number):
    """Python 3 çš„å››èˆäº”å…¥è¡Œä¸ºï¼Œå¤„ç† .5 çš„æƒ…å†µ"""
    rounded = round(number)
    if abs(number - rounded) == 0.5:
        return 2.0 * round(number / 2.0)
    return rounded

# --- COLMAP æ•°æ®åº“äº¤äº’ç±» ---

class COLMAPDatabase(sqlite3.Connection):
    """
    ä¸€ä¸ªå°è£…äº†ä¸COLMAP database.dbæ–‡ä»¶äº¤äº’çš„ç±»ã€‚
    æä¾›äº†åˆ›å»ºè¡¨å’ŒåŸºæœ¬æ“ä½œçš„æ–¹æ³•ã€‚
    """
    # SQL åˆ›å»ºè¡¨çš„è¯­å¥
    CREATE_CAMERAS_TABLE = """CREATE TABLE IF NOT EXISTS cameras (
        camera_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,
        model INTEGER NOT NULL,
        width INTEGER NOT NULL,
        height INTEGER NOT NULL,
        params BLOB,
        prior_focal_length INTEGER NOT NULL)"""
    CREATE_IMAGES_TABLE = f"""CREATE TABLE IF NOT EXISTS images (
        image_id INTEGER PRIMARY KEY AUTOINCREMENT NOT NULL,
        name TEXT NOT NULL UNIQUE,
        camera_id INTEGER NOT NULL,
        prior_qw REAL, prior_qx REAL, prior_qy REAL, prior_qz REAL,
        prior_tx REAL, prior_ty REAL, prior_tz REAL,
        CONSTRAINT image_id_check CHECK(image_id >= 0 and image_id < {MAX_IMAGE_ID}),
        FOREIGN KEY(camera_id) REFERENCES cameras(camera_id))"""
    CREATE_KEYPOINTS_TABLE = """CREATE TABLE IF NOT EXISTS keypoints (
        image_id INTEGER PRIMARY KEY NOT NULL,
        rows INTEGER NOT NULL, cols INTEGER NOT NULL, data BLOB,
        FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)"""
    CREATE_DESCRIPTORS_TABLE = """CREATE TABLE IF NOT EXISTS descriptors (
        image_id INTEGER PRIMARY KEY NOT NULL,
        rows INTEGER NOT NULL, cols INTEGER NOT NULL, data BLOB,
        FOREIGN KEY(image_id) REFERENCES images(image_id) ON DELETE CASCADE)"""
    CREATE_MATCHES_TABLE = """CREATE TABLE IF NOT EXISTS matches (
        pair_id INTEGER PRIMARY KEY NOT NULL,
        rows INTEGER NOT NULL, cols INTEGER NOT NULL, data BLOB)"""
    CREATE_TWO_VIEW_GEOMETRIES_TABLE = """CREATE TABLE IF NOT EXISTS two_view_geometries (
        pair_id INTEGER PRIMARY KEY NOT NULL,
        rows INTEGER NOT NULL, cols INTEGER NOT NULL, data BLOB,
        config INTEGER NOT NULL, F BLOB, E BLOB, H BLOB, qvec BLOB, tvec BLOB)"""
    CREATE_NAME_INDEX = "CREATE UNIQUE INDEX IF NOT EXISTS index_name ON images(name)"

    CREATE_ALL = "; ".join([
        CREATE_CAMERAS_TABLE, CREATE_IMAGES_TABLE, CREATE_KEYPOINTS_TABLE,
        CREATE_DESCRIPTORS_TABLE, CREATE_MATCHES_TABLE,
        CREATE_TWO_VIEW_GEOMETRIES_TABLE, CREATE_NAME_INDEX
    ])

    @staticmethod
    def connect(database_path):
        """é™æ€æ–¹æ³•ï¼Œç”¨äºè¿æ¥æ•°æ®åº“å¹¶è¿”å›ä¸€ä¸ªCOLMAPDatabaseå®ä¾‹"""
        return sqlite3.connect(database_path, factory=COLMAPDatabase)

    def __init__(self, *args, **kwargs):
        super(COLMAPDatabase, self).__init__(*args, **kwargs)
        # æä¾›ä¾¿æ·æ–¹æ³•æ¥åˆ›å»ºè¡¨
        self.create_tables = lambda: self.executescript(self.CREATE_ALL)

# --- ä¸»æµç¨‹å‡½æ•° ---

def pipeline(scene_path, n_views, llffhold=8):
    """
    å¯¹ä¸€ä¸ªå·²ç»å®ŒæˆCOLMAPç¨€ç–é‡å»ºçš„åœºæ™¯ï¼Œé€‰æ‹©ä¸€ä¸ªå­é›†è§†å›¾ï¼Œ
    å¹¶ä½¿ç”¨åŸå§‹çš„ç›¸æœºå†…å¤–å‚è¿›è¡Œé‡æ–°ä¸‰è§’æµ‹é‡ï¼Œæœ€åç”Ÿæˆç¨ å¯†ç‚¹äº‘ã€‚

    Args:
        scene_path (str): åœºæ™¯çš„ç»å¯¹è·¯å¾„ (ä¾‹å¦‚, '/workspace/llff/nerf_llff_data/flower')ã€‚
        n_views (int): è¦é€‰æ‹©ç”¨äºæ–°é‡å»ºçš„è§†å›¾æ•°é‡ã€‚
        llffhold (int): LLFFæ•°æ®é›†ä¸­ç”¨äºåˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†çš„å› å­ã€‚
    """
    print(f"\n===== ğŸ¬ Processing scene: {os.path.basename(scene_path)} with {n_views} views =====\n")

    # --- 1. è®¾ç½®è·¯å¾„å’Œåˆ›å»ºå·¥ä½œç›®å½• ---
    original_sparse_dir = os.path.join(scene_path, 'sparse', '0')
    original_images_dir = os.path.join(scene_path, 'images')

    if not os.path.isdir(original_sparse_dir):
        print(f"âŒ [ERROR]: Original sparse directory not found at: {original_sparse_dir}")
        sys.exit(1)

    work_dir_name = f"{n_views}_views_reconstruction"
    work_dir = os.path.join(scene_path, work_dir_name)

    if os.path.exists(work_dir):
        print(f"ğŸ§¹ [INFO]: Removing old working directory: {work_dir}")
        shutil.rmtree(work_dir)
    os.makedirs(work_dir)
    print(f"âœ… [INFO]: Created new working directory at: {work_dir}")

    # åˆ›å»ºå­ç›®å½•
    images_work_dir = os.path.join(work_dir, 'images')
    created_dir = os.path.join(work_dir, 'created') # å­˜æ”¾æˆ‘ä»¬æ‰‹åŠ¨åˆ›å»ºçš„ç›¸æœºå’Œå›¾åƒä¿¡æ¯
    triangulated_dir = os.path.join(work_dir, 'triangulated') # å­˜æ”¾ä¸‰è§’æµ‹é‡çš„ç»“æœ
    dense_dir = os.path.join(work_dir, 'dense') # å­˜æ”¾ç¨ å¯†é‡å»ºç»“æœ
    os.makedirs(images_work_dir)
    os.makedirs(created_dir)
    os.makedirs(triangulated_dir)

    db_path = os.path.join(work_dir, "database.db")

    # --- 2. ä»åŸå§‹æ¨¡å‹ä¸­è¯»å–ç›¸æœºå§¿æ€å¹¶ç­›é€‰å›¾åƒ ---
    print("\n--- ğŸ“ Reading original model and selecting images ---")
    
    # ä¸ºäº†è¯»å–æ–‡æœ¬æ–‡ä»¶ï¼Œå¦‚æœåŸå§‹æ¨¡å‹æ˜¯äºŒè¿›åˆ¶çš„ï¼Œå…ˆè½¬æ¢
    original_images_txt = os.path.join(original_sparse_dir, 'images.txt')
    if not os.path.exists(original_images_txt):
        print("    > Converting original sparse model to TXT format...")
        run_command(f"colmap model_converter --input_path {original_sparse_dir} --output_path {original_sparse_dir} --output_type TXT")

    images_data = {}
    with open(original_images_txt, "r") as fid:
        for line in fid:
            line = line.strip()
            if len(line) > 0 and line[0] != "#":
                elems = line.split()
                image_name = elems[9]
                # è·³è¿‡æ³¨é‡Šè¡Œ (ä¸‹ä¸€è¡Œæ˜¯3Dç‚¹)
                fid.readline()
                # å­˜å‚¨å›¾åƒååˆ°å…¶å§¿æ€å’Œç›¸æœºIDçš„æ˜ å°„
                images_data[image_name] = elems[1:]

    all_images = sorted(images_data.keys())
    
    # éµå¾ªLLFFæ•°æ®é›†çš„åˆ’åˆ†æ–¹å¼ï¼Œæ’é™¤æµ‹è¯•é›†
    train_img_list = [c for idx, c in enumerate(all_images) if idx % llffhold != 0]

    # ä»è®­ç»ƒé›†ä¸­å‡åŒ€é‡‡æ · n_views ä¸ªå›¾åƒ
    if n_views > 0 and n_views < len(train_img_list):
        indices = [int(round_python3(i)) for i in np.linspace(0, len(train_img_list) - 1, n_views)]
        selected_images = [train_img_list[i] for i in indices]
    else:
        selected_images = train_img_list

    print(f"ğŸ“¸ [INFO]: Selected {len(selected_images)} images for reconstruction.")
    for img_name in selected_images:
        shutil.copy(os.path.join(original_images_dir, img_name), os.path.join(images_work_dir, img_name))
    print(f"âœ… [INFO]: All {len(selected_images)} images copied.")


    # --- 3. ä¸ºæ–°çš„é‡å»ºå‡†å¤‡è¾“å…¥æ–‡ä»¶ ---
    print("\n--- ğŸ› ï¸ Preparing input files for triangulation ---")
    # æ‹·è´ç›¸æœºå†…å‚æ–‡ä»¶ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨åŸå§‹çš„ç›¸æœºæ¨¡å‹
    shutil.copy(os.path.join(original_sparse_dir, 'cameras.txt'), created_dir)
    
    # åˆ›å»ºä¸€ä¸ªç©ºçš„ 3D ç‚¹æ–‡ä»¶ï¼Œå› ä¸º `point_triangulator` ä¼šè‡ªå·±ç”Ÿæˆ
    with open(os.path.join(created_dir, 'points3D.txt'), "w") as fid:
        pass
        
    # --- 4. åœ¨å›¾åƒå­é›†ä¸Šè¿è¡Œç‰¹å¾æå–å’ŒåŒ¹é… ---
    print("\n--- ğŸŒŸ Starting Feature Extraction & Matching ğŸŒŸ ---")
    run_command(f"colmap feature_extractor --database_path {db_path} --image_path {images_work_dir}")
    run_command(f"colmap exhaustive_matcher --database_path {db_path}")
    
    # --- 5. åˆ›å»ºæ–°çš„ images.txtï¼Œä½¿ç”¨åŸå§‹å§¿æ€ ---
    print("\n--- âœï¸  Writing new 'images.txt' with original poses ---")
    db = COLMAPDatabase.connect(db_path)
    # æŒ‰COLMAPå†…éƒ¨å¤„ç†çš„é¡ºåºè·å–å›¾åƒå
    db_images = db.execute("SELECT name FROM images ORDER BY image_id")
    image_names_from_db = [row[0] for row in db_images]
    
    with open(os.path.join(created_dir, 'images.txt'), "w") as fid:
        for new_id, img_name in enumerate(image_names_from_db, 1):
            original_data = images_data[img_name]
            # æ ¼å¼: IMAGE_ID, QW, QX, QY, QZ, TX, TY, TZ, CAMERA_ID, NAME
            # æˆ‘ä»¬ä½¿ç”¨æ–°çš„ new_idï¼Œä½†ä¿ç•™åŸå§‹çš„å§¿æ€æ•°æ®
            line_data = [str(new_id)] + original_data
            fid.write(" ".join(line_data) + "\n\n") # COLMAPéœ€è¦ä¸€ä¸ªç©ºè¡Œ
    print("âœ… [INFO]: Successfully created 'images.txt' for the subset.")

    # --- 6. è¿è¡Œç‚¹ä¸‰è§’æµ‹é‡ ---
    print("\n--- ğŸŒŸ Starting Point Triangulation (using fixed poses) ğŸŒŸ ---")
    run_command(f"colmap point_triangulator "
                f"--database_path {db_path} "
                f"--image_path {images_work_dir} "
                f"--input_path {created_dir} "
                f"--output_path {triangulated_dir}")
    
    if not os.listdir(triangulated_dir):
        print("âŒ [FATAL]: Point triangulation failed to produce a model.")
        sys.exit(1)
    
    print("âœ… [SUCCESS]: Point triangulation completed.")
    
    # --- 7. è¿è¡Œç¨ å¯†é‡å»º ---
    print("\n--- ğŸŒŸ Starting Dense Reconstruction ğŸŒŸ ---")
    run_command(f"colmap image_undistorter "
                f"--image_path {images_work_dir} "
                f"--input_path {triangulated_dir} "
                f"--output_path {dense_dir} "
                f"--output_type COLMAP")

    run_command(f"colmap patch_match_stereo "
                f"--workspace_path {dense_dir} "
                f"--workspace_format COLMAP "
                f"--PatchMatchStereo.geom_consistency true")
                
    run_command(f"colmap stereo_fusion "
                f"--workspace_path {dense_dir} "
                f"--input_type geometric "
                f"--output_path {os.path.join(dense_dir, 'fused.ply')}")

    print("âœ… [SUCCESS]: Dense reconstruction completed successfully!")
    print(f"  > Dense point cloud saved to: {os.path.join(os.path.abspath(dense_dir), 'fused.ply')}")
    print("\nğŸ‰ All processes finished! ğŸ‰")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Run a COLMAP re-triangulation pipeline on a subset of images from an existing reconstruction.",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    parser.add_argument('--scene_path', required=True, type=str,
                        help="Absolute path to the scene directory (e.g., '/workspace/llff/nerf_llff_data/flower').")
    parser.add_argument('--n_views', required=True, type=int,
                        help="Number of views to select for the new reconstruction.")
    
    args = parser.parse_args()

    pipeline(scene_path=args.scene_path, n_views=args.n_views)
    
    # # ---- æˆ–è€…ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„è·¯å¾„è¿›è¡Œæµ‹è¯• ----
    # base_path = '/workspace/llff/nerf_llff_data/' # è¯·ç¡®ä¿è¿™æ˜¯ç»å¯¹è·¯å¾„!
    # for scene in ['flower']:
    #     scene_full_path = os.path.join(base_path, scene)
    #     pipeline(scene_path=scene_full_path, n_views=20)