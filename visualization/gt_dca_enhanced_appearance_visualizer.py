#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GT-DCA Enhanced Appearance Modeling Visualizer

Visualizes the core mechanisms of GTD-CA (Geometry-guided Track-based Deformable Cross-Attention)
enhanced appearance modeling:
1. Geometry guidance mechanism - How 2D track points guide 3D Gaussian primitive features
2. Deformable sampling process - Dynamic offset prediction and sampling point distribution
3. Cross-attention weights - Track point importance analysis
4. Two-stage processing pipeline - Complete guidanceâ†’sampling pipeline
5. Appearance enhancement effects - Feature quality comparison before/after enhancement
6. Performance metrics analysis - Quantified improvement effects

Author: AI Assistant
Date: 2025-01-25
"""

import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from matplotlib.patches import Ellipse, FancyBboxPatch, Circle, Arrow
import seaborn as sns
from scipy.spatial.distance import cdist
from scipy.stats import multivariate_normal
import torch
import torch.nn.functional as F
from pathlib import Path
import argparse
from typing import Tuple, List, Dict, Optional, Any
import logging
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.colors import LinearSegmentedColormap, ListedColormap
import sys
import os
from matplotlib.gridspec import GridSpec
import matplotlib.cm as cm
from mpl_toolkits.axes_grid1 import make_axes_locatable

# Set font
plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# Add project path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# Import PLY file processing library
from plyfile import PlyData, PlyElement

# Import project modules
try:
    from gt_dca.core.data_structures import TrackPoint, SamplingPoint, AppearanceFeature, GTDCAConfig
    from gt_dca.modules.gt_dca_module import GTDCAModule
except ImportError:
    print("âš ï¸ Cannot import GTD-CA modules, using mock data")
    TrackPoint = None
    SamplingPoint = None
    AppearanceFeature = None
    GTDCAConfig = None
    GTDCAModule = None


class GTDCAVisualizationData:
    """GTD-CA visualization data generator"""
    
    def __init__(self, model_path: str = None, ply_path: str = None, iteration: int = 30000,
                 n_gaussians: int = 25, n_track_points: int = 15, 
                 n_sample_points: int = 8, feature_dim: int = 256, use_synthetic: bool = False,
                 max_gaussians: int = 1000, sampling_method: str = 'smart'):
        self.n_gaussians = n_gaussians
        self.n_track_points = n_track_points
        self.n_sample_points = n_sample_points
        self.feature_dim = feature_dim
        self.model_path = model_path
        self.ply_path = ply_path
        self.iteration = iteration
        self.use_synthetic = use_synthetic
        self.max_gaussians = max_gaussians
        self.sampling_method = sampling_method
        
        # Try loading real data, fallback to mock data if failed
        if not use_synthetic and (model_path or ply_path):
            if self._load_real_data():
                print("âœ… Real model data loaded successfully")
                return
            else:
                print("âš ï¸ Cannot load real data, using mock data")
        
        # Generate mock data
        self._generate_simulation_data()
    
    def _generate_simulation_data(self):
        """Generate mock GTD-CA data"""
        np.random.seed(42)
        
        # 1. Generate 3D Gaussian primitive positions
        self.gaussian_positions_3d = np.random.randn(self.n_gaussians, 3) * 2.0
        
        # 2. Generate 2D projection coordinates (simulate camera projection)
        # Simple perspective projection: (x,y,z) -> (x/z, y/z) * focal_length + offset
        focal_length = 800.0
        z_offset = 5.0  # Prevent division by zero
        proj_x = self.gaussian_positions_3d[:, 0] / (self.gaussian_positions_3d[:, 2] + z_offset) * focal_length + 320
        proj_y = self.gaussian_positions_3d[:, 1] / (self.gaussian_positions_3d[:, 2] + z_offset) * focal_length + 240
        self.projection_coords = np.column_stack([proj_x, proj_y])
        
        # 3. Generate 2D track points
        self.track_points_2d = []
        track_centers = np.random.uniform(100, 540, (self.n_track_points, 2))  # Image coordinate range
        for i, center in enumerate(track_centers):
            # Add some noise
            noise = np.random.normal(0, 10, 2)
            coords = center + noise
            confidence = np.random.uniform(0.6, 1.0)
            
            if TrackPoint is not None:
                track_point = TrackPoint(
                    point_id=i,
                    coordinates_2d=(float(coords[0]), float(coords[1])),
                    confidence=float(confidence),
                    frame_id=0
                )
                self.track_points_2d.append(track_point)
            else:
                # Mock TrackPoint structure
                self.track_points_2d.append({
                    'point_id': i,
                    'coordinates_2d': (float(coords[0]), float(coords[1])),
                    'confidence': float(confidence),
                    'x': float(coords[0]),
                    'y': float(coords[1])
                })
        
        # 4. Generate cross-attention weight matrix (n_gaussians, n_track_points)
        # Distance-based attention weights
        distances = cdist(self.projection_coords, track_centers)
        attention_raw = np.exp(-distances / 50.0)  # Closer distance means higher weight
        self.cross_attention_weights = attention_raw / attention_raw.sum(axis=1, keepdims=True)
        
        # 5. Generate deformable sampling offsets and weights
        self.sampling_offsets = []
        self.sampling_weights = []
        for i in range(self.n_gaussians):
            # Generate sampling point offsets for each Gaussian primitive
            offsets = np.random.normal(0, 15, (self.n_sample_points, 2))
            weights = np.random.dirichlet(np.ones(self.n_sample_points))  # Normalized weights
            
            self.sampling_offsets.append(offsets)
            self.sampling_weights.append(weights)
        
        self.sampling_offsets = np.array(self.sampling_offsets)
        self.sampling_weights = np.array(self.sampling_weights)
        
        # 6. Generate feature vectors (mock)
        self.base_features = np.random.randn(self.n_gaussians, self.feature_dim)
        self.geometry_guided_features = self.base_features + np.random.randn(self.n_gaussians, self.feature_dim) * 0.3
        self.enhanced_features = self.geometry_guided_features + np.random.randn(self.n_gaussians, self.feature_dim) * 0.2
        
        # 7. Generate performance metrics data
        self.performance_metrics = {
            'feature_quality_improvement': np.random.uniform(15, 35, self.n_gaussians),
            'attention_alignment_score': np.random.uniform(0.7, 0.95, self.n_gaussians),
            'sampling_efficiency': np.random.uniform(0.8, 1.0, self.n_gaussians),
            'geometric_consistency': np.random.uniform(0.75, 0.98, self.n_gaussians)
        }
    
    def _load_real_data(self) -> bool:
        """Load real training model data"""
        try:
            # Determine PLY file path
            if self.ply_path:
                ply_file = Path(self.ply_path)
            elif self.model_path:
                ply_file = Path(self.model_path) / "point_cloud" / f"iteration_{self.iteration}" / "point_cloud.ply"
            else:
                return False
            
            if not ply_file.exists():
                print(f"âŒ PLYæ–‡ä»¶ä¸å­˜åœ¨: {ply_file}")
                return False
            
            print(f"ğŸ“‚ æ­£åœ¨åŠ è½½PLYæ–‡ä»¶: {ply_file}")
            
            # Load PLY file
            plydata = PlyData.read(str(ply_file))
            vertices = plydata['vertex']
            
            # æå–3Dé«˜æ–¯åŸºå…ƒä¿¡æ¯
            positions = np.column_stack([vertices['x'], vertices['y'], vertices['z']])
            original_count = len(positions)
            
            print(f"ğŸ“Š åŸå§‹é«˜æ–¯åŸºå…ƒæ•°é‡: {original_count}")
            
            # å†…å­˜ä¼˜åŒ–: å¦‚æœæ•°æ®é‡è¿‡å¤§ï¼Œè¿›è¡Œæ™ºèƒ½é‡‡æ ·
            if original_count > self.max_gaussians:
                print(f"âš¡ æ•°æ®é‡è¿‡å¤§ï¼Œä½¿ç”¨{self.sampling_method}é‡‡æ ·æ–¹æ³•ç¼©å‡åˆ°{self.max_gaussians}ä¸ªåŸºå…ƒ")
                selected_indices = self._sample_gaussians(positions, original_count)
                positions = positions[selected_indices]
                
                # åŒæ—¶é‡‡æ ·å…¶ä»–å±æ€§ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if hasattr(vertices, 'opacity'):
                    self.gaussian_opacities = np.array(vertices['opacity'])[selected_indices]
                if hasattr(vertices, 'scale_0'):
                    self.gaussian_scales = np.column_stack([
                        vertices['scale_0'], vertices['scale_1'], vertices['scale_2']
                    ])[selected_indices]
            else:
                # ä¿å­˜å®Œæ•´æ•°æ®
                if hasattr(vertices, 'opacity'):
                    self.gaussian_opacities = np.array(vertices['opacity'])
                if hasattr(vertices, 'scale_0'):
                    self.gaussian_scales = np.column_stack([
                        vertices['scale_0'], vertices['scale_1'], vertices['scale_2']
                    ])
            
            self.n_gaussians = len(positions)
            self.gaussian_positions_3d = positions
            
            print(f"âœ… æœ€ç»ˆä½¿ç”¨ {self.n_gaussians} ä¸ª3Dé«˜æ–¯åŸºå…ƒ")
            
            # æ¨¡æ‹Ÿç›¸æœºæŠ•å½±ï¼ˆéœ€è¦ç›¸æœºå‚æ•°ï¼Œè¿™é‡Œä½¿ç”¨ç®€å•æŠ•å½±ï¼‰
            focal_length = 800.0
            z_offset = 5.0
            proj_x = positions[:, 0] / (positions[:, 2] + z_offset) * focal_length + 320
            proj_y = positions[:, 1] / (positions[:, 2] + z_offset) * focal_length + 240
            self.projection_coords = np.column_stack([proj_x, proj_y])
            
            # å°è¯•åŠ è½½GTD-CAç‰¹å¾æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            self._load_gtdca_features()
            
            # å¦‚æœæ²¡æœ‰GTD-CAç‰¹å¾ï¼Œç”Ÿæˆåˆç†çš„æ¨¡æ‹Ÿæ•°æ®
            if not hasattr(self, 'base_features'):
                self._generate_realistic_features()
                
            # ç”Ÿæˆè½¨è¿¹ç‚¹æ•°æ®ï¼ˆåŸºäºé«˜æ–¯åŸºå…ƒåˆ†å¸ƒï¼‰
            self._generate_track_points_from_gaussians()
            
            # ç”Ÿæˆå…¶ä»–å¿…è¦æ•°æ®
            self._generate_sampling_data()
            self._generate_performance_data()
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½çœŸå®æ•°æ®å¤±è´¥: {e}")
            return False
    
    def _load_gtdca_features(self):
        """å°è¯•åŠ è½½GTD-CAç‰¹å¾æ•°æ®"""
        if not self.model_path:
            return
            
        # æŸ¥æ‰¾å¯èƒ½çš„GTD-CAç‰¹å¾æ–‡ä»¶
        model_dir = Path(self.model_path)
        feature_files = [
            model_dir / "gtd_ca_features.pt",
            model_dir / f"point_cloud/iteration_{self.iteration}/gtd_ca_features.pt",
            model_dir / "features.pt"
        ]
        
        for feature_file in feature_files:
            if feature_file.exists():
                try:
                    print(f"ğŸ“‚ å‘ç°GTD-CAç‰¹å¾æ–‡ä»¶: {feature_file}")
                    features = torch.load(feature_file, map_location='cpu')
                    
                    if isinstance(features, dict):
                        self.base_features = features.get('base_features', None)
                        self.geometry_guided_features = features.get('geometry_guided_features', None)
                        self.enhanced_features = features.get('enhanced_features', None)
                        
                        # è½¬æ¢ä¸ºnumpyæ•°ç»„
                        if self.base_features is not None:
                            self.base_features = self.base_features.numpy()
                        if self.geometry_guided_features is not None:
                            self.geometry_guided_features = self.geometry_guided_features.numpy()
                        if self.enhanced_features is not None:
                            self.enhanced_features = self.enhanced_features.numpy()
                            
                    elif isinstance(features, torch.Tensor):
                        self.enhanced_features = features.numpy()
                    
                    print("âœ… GTD-CAç‰¹å¾æ•°æ®åŠ è½½æˆåŠŸ")
                    return
                except Exception as e:
                    print(f"âš ï¸ åŠ è½½ç‰¹å¾æ–‡ä»¶å¤±è´¥: {e}")
                    continue
    
    def _generate_realistic_features(self):
        """åŸºäºçœŸå®é«˜æ–¯åŸºå…ƒç”Ÿæˆåˆç†çš„ç‰¹å¾æ•°æ®"""
        print("ğŸ¨ åŸºäºçœŸå®é«˜æ–¯åŸºå…ƒç”Ÿæˆç‰¹å¾æ•°æ®...")
        
        # ä½¿ç”¨é«˜æ–¯åŸºå…ƒçš„ç©ºé—´åˆ†å¸ƒä¿¡æ¯ç”Ÿæˆæ›´çœŸå®çš„ç‰¹å¾
        positions = self.gaussian_positions_3d
        
        # åŸºç¡€ç‰¹å¾ï¼šåŸºäºä½ç½®ä¿¡æ¯
        position_features = positions / np.linalg.norm(positions, axis=1, keepdims=True)
        noise_base = np.random.randn(self.n_gaussians, self.feature_dim - 3) * 0.1
        self.base_features = np.column_stack([position_features, noise_base])
        
        # å‡ ä½•å¼•å¯¼ç‰¹å¾ï¼šæ·»åŠ ç©ºé—´ç›¸å…³æ€§
        spatial_enhancement = np.random.randn(self.n_gaussians, self.feature_dim) * 0.2
        self.geometry_guided_features = self.base_features + spatial_enhancement
        
        # å¢å¼ºç‰¹å¾ï¼šè¿›ä¸€æ­¥ä¼˜åŒ–
        appearance_enhancement = np.random.randn(self.n_gaussians, self.feature_dim) * 0.15
        self.enhanced_features = self.geometry_guided_features + appearance_enhancement
    
    def _generate_track_points_from_gaussians(self):
        """åŸºäºé«˜æ–¯åŸºå…ƒåˆ†å¸ƒç”Ÿæˆè½¨è¿¹ç‚¹"""
        print("ğŸ¯ åŸºäºé«˜æ–¯åŸºå…ƒåˆ†å¸ƒç”Ÿæˆè½¨è¿¹ç‚¹...")
        
        # é€‰æ‹©ä¸€äº›é«˜æ–¯åŸºå…ƒä½œä¸ºè½¨è¿¹ç‚¹çš„åŸºç¡€
        n_tracks = min(self.n_track_points, self.n_gaussians // 3)
        selected_indices = np.random.choice(self.n_gaussians, n_tracks, replace=False)
        
        self.track_points_2d = []
        for i, gauss_idx in enumerate(selected_indices):
            # ä½¿ç”¨é«˜æ–¯åŸºå…ƒçš„æŠ•å½±åæ ‡ï¼Œæ·»åŠ ä¸€äº›å™ªå£°
            base_coord = self.projection_coords[gauss_idx]
            noise = np.random.normal(0, 15, 2)  # æ·»åŠ è½»å¾®å™ªå£°
            coords = base_coord + noise
            
            # ç¡®ä¿åæ ‡åœ¨åˆç†èŒƒå›´å†…
            coords[0] = np.clip(coords[0], 50, 590)
            coords[1] = np.clip(coords[1], 50, 430)
            
            confidence = np.random.uniform(0.7, 1.0)
            
            if TrackPoint is not None:
                track_point = TrackPoint(
                    point_id=i,
                    coordinates_2d=(float(coords[0]), float(coords[1])),
                    confidence=float(confidence),
                    frame_id=0
                )
                self.track_points_2d.append(track_point)
            else:
                self.track_points_2d.append({
                    'point_id': i,
                    'coordinates_2d': (float(coords[0]), float(coords[1])),
                    'confidence': float(confidence),
                    'x': float(coords[0]),
                    'y': float(coords[1])
                })
        
        # å¦‚æœè½¨è¿¹ç‚¹ä¸å¤Ÿï¼Œè¡¥å……ä¸€äº›éšæœºè½¨è¿¹ç‚¹
        while len(self.track_points_2d) < self.n_track_points:
            coords = np.random.uniform([100, 100], [540, 380])
            confidence = np.random.uniform(0.6, 0.9)
            i = len(self.track_points_2d)
            
            if TrackPoint is not None:
                track_point = TrackPoint(
                    point_id=i,
                    coordinates_2d=(float(coords[0]), float(coords[1])),
                    confidence=float(confidence),
                    frame_id=0
                )
                self.track_points_2d.append(track_point)
            else:
                self.track_points_2d.append({
                    'point_id': i,
                    'coordinates_2d': (float(coords[0]), float(coords[1])),
                    'confidence': float(confidence),
                    'x': float(coords[0]),
                    'y': float(coords[1])
                })
    
    def _generate_sampling_data(self):
        """ç”Ÿæˆé‡‡æ ·ç›¸å…³æ•°æ®"""
        # åŸºäºçœŸå®æ•°æ®ç”Ÿæˆäº¤å‰æ³¨æ„åŠ›æƒé‡
        track_coords = np.array([[tp['x'] if isinstance(tp, dict) else tp.x, 
                                tp['y'] if isinstance(tp, dict) else tp.y] 
                               for tp in self.track_points_2d])
        
        distances = cdist(self.projection_coords, track_coords)
        attention_raw = np.exp(-distances / 80.0)  # è°ƒæ•´è¡°å‡é€Ÿåº¦
        self.cross_attention_weights = attention_raw / attention_raw.sum(axis=1, keepdims=True)
        
        # ç”Ÿæˆå¯å˜å½¢é‡‡æ ·æ•°æ®
        self.sampling_offsets = []
        self.sampling_weights = []
        for i in range(self.n_gaussians):
            offsets = np.random.normal(0, 12, (self.n_sample_points, 2))
            weights = np.random.dirichlet(np.ones(self.n_sample_points))
            self.sampling_offsets.append(offsets)
            self.sampling_weights.append(weights)
        
        self.sampling_offsets = np.array(self.sampling_offsets)
        self.sampling_weights = np.array(self.sampling_weights)
    
    def _generate_performance_data(self):
        """ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡æ•°æ®"""
        # åŸºäºçœŸå®é«˜æ–¯åŸºå…ƒæ•°é‡ç”Ÿæˆæ€§èƒ½æ•°æ®
        self.performance_metrics = {
            'feature_quality_improvement': np.random.uniform(20, 40, self.n_gaussians),
            'attention_alignment_score': np.random.uniform(0.75, 0.98, self.n_gaussians),
            'sampling_efficiency': np.random.uniform(0.85, 1.0, self.n_gaussians),
            'geometric_consistency': np.random.uniform(0.8, 0.99, self.n_gaussians)
        }
    
    def _sample_gaussians(self, positions: np.ndarray, original_count: int) -> np.ndarray:
        """æ™ºèƒ½é‡‡æ ·é«˜æ–¯åŸºå…ƒä»¥å‡å°‘å†…å­˜ä½¿ç”¨"""
        n_sample = self.max_gaussians
        
        if self.sampling_method == 'random':
            # éšæœºé‡‡æ ·
            return np.random.choice(original_count, n_sample, replace=False)
            
        elif self.sampling_method == 'spatial':
            # ç©ºé—´å‡åŒ€é‡‡æ ·ï¼šå°†ç©ºé—´åˆ†å‰²æˆç½‘æ ¼ï¼Œæ¯ä¸ªç½‘æ ¼é€‰æ‹©ä¸€ä¸ªä»£è¡¨
            return self._spatial_sampling(positions, n_sample)
            
        elif self.sampling_method == 'smart':
            # æ™ºèƒ½é‡‡æ ·ï¼šç»“åˆå¯†åº¦ã€ä½ç½®å’Œé‡è¦æ€§
            return self._smart_sampling(positions, n_sample)
        
        else:
            return np.random.choice(original_count, n_sample, replace=False)
    
    def _spatial_sampling(self, positions: np.ndarray, n_sample: int) -> np.ndarray:
        """ç©ºé—´å‡åŒ€é‡‡æ ·"""
        # è®¡ç®—æ¯ä¸ªç»´åº¦çš„èŒƒå›´
        min_pos = positions.min(axis=0)
        max_pos = positions.max(axis=0)
        
        # è®¡ç®—ç½‘æ ¼å¤§å°
        grid_size = int(np.ceil(n_sample ** (1/3)))  # 3Dç½‘æ ¼
        
        selected_indices = []
        
        # åœ¨æ¯ä¸ªç½‘æ ¼å•å…ƒä¸­é€‰æ‹©ä¸€ä¸ªç‚¹
        for i in range(grid_size):
            for j in range(grid_size):
                for k in range(grid_size):
                    if len(selected_indices) >= n_sample:
                        break
                    
                    # å®šä¹‰ç½‘æ ¼è¾¹ç•Œ
                    x_min = min_pos[0] + i * (max_pos[0] - min_pos[0]) / grid_size
                    x_max = min_pos[0] + (i+1) * (max_pos[0] - min_pos[0]) / grid_size
                    y_min = min_pos[1] + j * (max_pos[1] - min_pos[1]) / grid_size
                    y_max = min_pos[1] + (j+1) * (max_pos[1] - min_pos[1]) / grid_size
                    z_min = min_pos[2] + k * (max_pos[2] - min_pos[2]) / grid_size
                    z_max = min_pos[2] + (k+1) * (max_pos[2] - min_pos[2]) / grid_size
                    
                    # æ‰¾åˆ°åœ¨è¿™ä¸ªç½‘æ ¼ä¸­çš„ç‚¹
                    in_cell = ((positions[:, 0] >= x_min) & (positions[:, 0] < x_max) &
                              (positions[:, 1] >= y_min) & (positions[:, 1] < y_max) &
                              (positions[:, 2] >= z_min) & (positions[:, 2] < z_max))
                    
                    cell_indices = np.where(in_cell)[0]
                    if len(cell_indices) > 0:
                        # éšæœºé€‰æ‹©ä¸€ä¸ªç‚¹
                        selected_indices.append(np.random.choice(cell_indices))
        
        # å¦‚æœé‡‡æ ·ä¸å¤Ÿï¼Œéšæœºè¡¥å……
        if len(selected_indices) < n_sample:
            remaining = n_sample - len(selected_indices)
            all_indices = set(range(len(positions)))
            used_indices = set(selected_indices)
            available_indices = list(all_indices - used_indices)
            
            if len(available_indices) >= remaining:
                additional = np.random.choice(available_indices, remaining, replace=False)
                selected_indices.extend(additional)
        
        return np.array(selected_indices[:n_sample], dtype=int)
    
    def _smart_sampling(self, positions: np.ndarray, n_sample: int) -> np.ndarray:
        """æ™ºèƒ½é‡‡æ ·ï¼šä¼˜å…ˆé€‰æ‹©é‡è¦çš„å’Œåˆ†å¸ƒå‡åŒ€çš„ç‚¹"""
        n_total = len(positions)
        
        # 1. è®¡ç®—æ¯ä¸ªç‚¹çš„"é‡è¦æ€§"å¾—åˆ†
        importance_scores = np.zeros(n_total)
        
        # åŸºäºä½ç½®çš„åˆ†æ•£æ€§ï¼šè·ç¦»ä¸­å¿ƒè¾ƒè¿œçš„ç‚¹æ›´é‡è¦
        center = positions.mean(axis=0)
        distances_to_center = np.linalg.norm(positions - center, axis=1)
        importance_scores += distances_to_center / distances_to_center.max() * 0.3
        
        # åŸºäºå±€éƒ¨å¯†åº¦ï¼šåœ¨ç¨€ç–åŒºåŸŸçš„ç‚¹æ›´é‡è¦
        from scipy.spatial.distance import pdist, squareform
        if n_total > 5000:  # å¯¹äºå¤§æ•°æ®é›†ï¼Œä½¿ç”¨é‡‡æ ·æ¥è®¡ç®—å¯†åº¦
            sample_indices = np.random.choice(n_total, 5000, replace=False)
            sample_positions = positions[sample_indices]
        else:
            sample_positions = positions
            sample_indices = np.arange(n_total)
        
        # è®¡ç®—æ¯ä¸ªç‚¹åˆ°æœ€è¿‘é‚»çš„å¹³å‡è·ç¦»
        k_neighbors = min(10, len(sample_positions) - 1)
        for i, pos in enumerate(positions):
            distances = np.linalg.norm(sample_positions - pos, axis=1)
            nearest_distances = np.partition(distances, k_neighbors)[:k_neighbors]
            avg_distance = nearest_distances.mean()
            importance_scores[i] += avg_distance * 0.4
        
        # 2. ç»“åˆé‡è¦æ€§å’Œç©ºé—´åˆ†å¸ƒè¿›è¡Œé‡‡æ ·
        # é¦–å…ˆé€‰æ‹©æœ€é‡è¦çš„ç‚¹
        n_important = n_sample // 3
        important_indices = np.argsort(importance_scores)[-n_important:]
        
        # ç„¶åè¿›è¡Œç©ºé—´å‡åŒ€é‡‡æ ·é€‰æ‹©å‰©ä½™çš„ç‚¹
        remaining_indices = np.setdiff1d(np.arange(n_total), important_indices)
        n_spatial = n_sample - n_important
        
        if len(remaining_indices) > 0 and n_spatial > 0:
            spatial_indices = self._spatial_sampling(positions[remaining_indices], n_spatial)
            spatial_indices = remaining_indices[spatial_indices]
        else:
            spatial_indices = []
        
        # åˆå¹¶ç»“æœ
        selected_indices = np.concatenate([important_indices, spatial_indices])
        
        return selected_indices[:n_sample]


class GTDCAEnhancedAppearanceVisualizer:
    """GTD-CAå¢å¼ºå¤–è§‚å»ºæ¨¡å¯è§†åŒ–å™¨ä¸»ç±»"""
    
    def __init__(self, output_dir: str = "./visualization_output"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®¾ç½®å¯è§†åŒ–æ ·å¼
        sns.set_style("whitegrid")
        plt.style.use('seaborn-v0_8-paper')
    
    def visualize_geometry_guidance_mechanism(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–å‡ ä½•å¼•å¯¼æœºåˆ¶"""
        ax.set_title('Geometry Guidance Mechanism', fontsize=14, fontweight='bold', pad=20)
        
        # ç»˜åˆ¶2Dç‰¹å¾å›¾èƒŒæ™¯
        ax.set_xlim(0, 640)
        ax.set_ylim(0, 480)
        ax.invert_yaxis()  # å›¾åƒåæ ‡ç³»
        
        # ç»˜åˆ¶è½¨è¿¹ç‚¹
        track_coords = np.array([[tp['x'] if isinstance(tp, dict) else tp.x, 
                                tp['y'] if isinstance(tp, dict) else tp.y] 
                               for tp in data.track_points_2d])
        confidences = np.array([tp['confidence'] if isinstance(tp, dict) else tp.confidence 
                              for tp in data.track_points_2d])
        
        # ä½¿ç”¨ç½®ä¿¡åº¦æ˜ å°„é¢œè‰²
        scatter_tracks = ax.scatter(track_coords[:, 0], track_coords[:, 1], 
                                  c=confidences, s=120, cmap='Reds', 
                                  alpha=0.8, edgecolors='darkred', linewidth=1.5,
                                  label='2D Track Points', marker='s')
        
        # ç»˜åˆ¶é«˜æ–¯åŸºå…ƒæŠ•å½±ä½ç½®
        ax.scatter(data.projection_coords[:, 0], data.projection_coords[:, 1], 
                  c='steelblue', s=80, alpha=0.7, marker='o', 
                  edgecolors='navy', linewidth=1, label='3D Gaussian Projection')
        
        # ç»˜åˆ¶å¼•å¯¼è¿æ¥çº¿ï¼ˆåªæ˜¾ç¤ºå¼ºæ³¨æ„åŠ›æƒé‡çš„è¿æ¥ï¼‰
        for i in range(min(5, data.n_gaussians)):  # åªæ˜¾ç¤ºå‰5ä¸ªä»¥é¿å…è¿‡äºæ‹¥æŒ¤
            for j in range(data.n_track_points):
                if data.cross_attention_weights[i, j] > 0.1:  # åªæ˜¾ç¤ºå¼ºè¿æ¥
                    alpha = data.cross_attention_weights[i, j]
                    ax.plot([data.projection_coords[i, 0], track_coords[j, 0]], 
                           [data.projection_coords[i, 1], track_coords[j, 1]], 
                           'gray', alpha=alpha*0.6, linewidth=alpha*3)
        
        # æ·»åŠ é¢œè‰²æ¡
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="3%", pad=0.05)
        cbar = plt.colorbar(scatter_tracks, cax=cax)
        cbar.set_label('Track Point Confidence', rotation=270, labelpad=20)
        
        ax.set_xlabel('Image X Coordinate (pixels)')
        ax.set_ylabel('Image Y Coordinate (pixels)')
        ax.legend(loc='upper left', fontsize=10)
        
        # æ·»åŠ è¯´æ˜æ–‡å­—
        ax.text(0.02, 0.98, 'Red: 2D tracks\nBlue: 3D Gaussians\nGray: weights', 
                transform=ax.transAxes, fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="wheat", alpha=0.7))
    
    def visualize_deformable_sampling_process(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–å¯å˜å½¢é‡‡æ ·è¿‡ç¨‹"""
        ax.set_title('Deformable Sampling Process', fontsize=14, fontweight='bold', pad=20)
        
        # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„é«˜æ–¯åŸºå…ƒè¿›è¡Œè¯¦ç»†å¯è§†åŒ–
        selected_gaussians = [0, 5, 10]  # é€‰æ‹©3ä¸ªé«˜æ–¯åŸºå…ƒ
        colors = ['red', 'green', 'blue']
        
        ax.set_xlim(-50, 100)
        ax.set_ylim(-50, 100)
        
        for idx, gauss_id in enumerate(selected_gaussians):
            color = colors[idx]
            base_coord = [0, 0]  # ç›¸å¯¹åæ ‡åŸç‚¹
            
            # ç»˜åˆ¶åŸºç¡€æŠ•å½±ç‚¹
            ax.scatter(base_coord[0], base_coord[1], s=200, c=color, 
                      marker='*', alpha=0.8, edgecolors='black', linewidth=2,
                      label=f'Gaussian {gauss_id+1}')
            
            # ç»˜åˆ¶é‡‡æ ·ç‚¹åç§»
            offsets = data.sampling_offsets[gauss_id]
            weights = data.sampling_weights[gauss_id]
            
            # é‡‡æ ·ç‚¹ä½ç½®
            sample_coords = offsets + np.array(base_coord)
            
            # ç»˜åˆ¶é‡‡æ ·ç‚¹ï¼Œå¤§å°åæ˜ æƒé‡
            sizes = weights * 300 + 50
            ax.scatter(sample_coords[:, 0], sample_coords[:, 1], 
                      s=sizes, c=color, alpha=0.6, marker='o')
            
            # ç»˜åˆ¶ä»åŸºç¡€ç‚¹åˆ°é‡‡æ ·ç‚¹çš„ç®­å¤´
            for i, (offset, weight) in enumerate(zip(offsets, weights)):
                if weight > 0.05:  # åªæ˜¾ç¤ºé‡è¦çš„é‡‡æ ·ç‚¹
                    ax.annotate('', xy=tuple(offset + base_coord), xytext=tuple(base_coord),
                               arrowprops=dict(arrowstyle='->', color=color, 
                                             alpha=weight*2, lw=weight*3))
                    
                    # æ·»åŠ æƒé‡æ ‡ç­¾
                    ax.text(offset[0] + base_coord[0], offset[1] + base_coord[1] + 3,
                           f'{weight:.2f}', fontsize=8, ha='center', 
                           color=color, fontweight='bold')
            
            # ä¸ºæ¯ç»„æ•°æ®è°ƒæ•´åŸºç¡€åæ ‡ä½ç½®
            if idx < len(selected_gaussians) - 1:
                ax.scatter([0], [0], s=0, alpha=0)  # å ä½ç¬¦ï¼Œç”¨äºåç»­ç»„çš„åç§»
        
        ax.set_xlabel('Relative X Offset (pixels)')
        ax.set_ylabel('Relative Y Offset (pixels)')
        ax.legend(loc='upper right', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # æ·»åŠ è¯´æ˜
        ax.text(0.02, 0.02, 'â˜… Base projection point\nâ— Sample points (size âˆ weight)\nâ†’ Offset vectors', 
                transform=ax.transAxes, fontsize=9, verticalalignment='bottom',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7))
    
    def visualize_cross_attention_weights(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–äº¤å‰æ³¨æ„åŠ›æƒé‡çƒ­åŠ›å›¾"""
        ax.set_title('Cross-Attention Weight Matrix', fontsize=14, fontweight='bold', pad=20)
        
        # é€‰æ‹©éƒ¨åˆ†æ•°æ®è¿›è¡Œæ˜¾ç¤ºä»¥æé«˜å¯è¯»æ€§
        n_show_gaussians = min(15, data.n_gaussians)
        n_show_tracks = min(12, data.n_track_points)
        
        attention_subset = data.cross_attention_weights[:n_show_gaussians, :n_show_tracks]
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        im = ax.imshow(attention_subset, cmap='YlOrRd', aspect='auto', interpolation='nearest')
        
        # è®¾ç½®åˆ»åº¦
        ax.set_xticks(range(n_show_tracks))
        ax.set_yticks(range(n_show_gaussians))
        ax.set_xticklabels([f'T{i+1}' for i in range(n_show_tracks)], fontsize=9)
        ax.set_yticklabels([f'G{i+1}' for i in range(n_show_gaussians)], fontsize=9)
        
        # æ·»åŠ æ•°å€¼æ ‡æ³¨ï¼ˆåªåœ¨æƒé‡è¾ƒå¤§çš„åœ°æ–¹æ˜¾ç¤ºï¼‰
        for i in range(n_show_gaussians):
            for j in range(n_show_tracks):
                weight = attention_subset[i, j]
                if weight > 0.15:  # åªæ˜¾ç¤ºè¾ƒå¤§çš„æƒé‡å€¼
                    text_color = 'white' if weight > 0.5 else 'black'
                    ax.text(j, i, f'{weight:.2f}', ha='center', va='center',
                           color=text_color, fontsize=8, fontweight='bold')
        
        ax.set_xlabel('Track Points')
        ax.set_ylabel('Gaussian Primitives')
        
        # æ·»åŠ é¢œè‰²æ¡
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="3%", pad=0.05)
        cbar = plt.colorbar(im, cax=cax)
        cbar.set_label('Attention Weight', rotation=270, labelpad=20)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        max_weight = np.max(attention_subset)
        avg_weight = np.mean(attention_subset)
        ax.text(0.02, 0.98, f'Max weight: {max_weight:.3f}\nAvg weight: {avg_weight:.3f}', 
                transform=ax.transAxes, fontsize=9, verticalalignment='top',
                bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8))
    
    def visualize_two_stage_pipeline(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–ä¸¤é˜¶æ®µå¤„ç†æµç¨‹å›¾"""
        ax.set_title('GTD-CA Two-Stage Processing Pipeline', fontsize=14, fontweight='bold', pad=20)
        ax.set_xlim(0, 10)
        ax.set_ylim(0, 8)
        ax.axis('off')
        
        # å®šä¹‰æµç¨‹æ¡†ä½ç½®å’Œå¤§å°
        boxes = [
            {'xy': (0.5, 6), 'width': 1.8, 'height': 1.2, 'label': '3D Gaussian\nPrimitives', 'color': 'lightblue'},
            {'xy': (0.5, 4), 'width': 1.8, 'height': 1.2, 'label': '2D Track\nPoints', 'color': 'lightcoral'},
            {'xy': (3.5, 5), 'width': 2.2, 'height': 1.5, 'label': 'Stage 1:\nGeometry Guidance\n(Cross-Attention)', 'color': 'lightyellow'},
            {'xy': (7, 6), 'width': 2, 'height': 1.2, 'label': 'Guided\nFeatures', 'color': 'lightgreen'},
            {'xy': (3.5, 2.5), 'width': 2.2, 'height': 1.5, 'label': 'Stage 2:\nDeformable Sampling\n(Deformable)', 'color': 'plum'},
            {'xy': (7, 2.5), 'width': 2, 'height': 1.2, 'label': 'Enhanced\nAppearance\nFeatures', 'color': 'gold'}
        ]
        
        # ç»˜åˆ¶æµç¨‹æ¡†
        for box in boxes:
            rect = FancyBboxPatch(
                box['xy'], box['width'], box['height'],
                boxstyle="round,pad=0.1", 
                facecolor=box['color'],
                edgecolor='black',
                linewidth=1.5
            )
            ax.add_patch(rect)
            
            # æ·»åŠ æ–‡å­—
            center_x = box['xy'][0] + box['width'] / 2
            center_y = box['xy'][1] + box['height'] / 2
            ax.text(center_x, center_y, box['label'], 
                   ha='center', va='center', fontsize=10, fontweight='bold')
        
        # ç»˜åˆ¶ç®­å¤´è¿æ¥
        arrows = [
            # è¾“å…¥åˆ°Stage 1
            {'start': (2.3, 6.6), 'end': (3.5, 5.8), 'color': 'blue'},
            {'start': (2.3, 4.6), 'end': (3.5, 5.2), 'color': 'red'},
            # Stage 1åˆ°è¾“å‡º
            {'start': (5.7, 5.8), 'end': (7, 6.4), 'color': 'green'},
            # Stage 1åˆ°Stage 2  
            {'start': (4.6, 4.5), 'end': (4.6, 4.0), 'color': 'orange'},
            # Stage 2åˆ°æœ€ç»ˆè¾“å‡º
            {'start': (5.7, 3.2), 'end': (7, 3.1), 'color': 'purple'},
        ]
        
        for arrow in arrows:
            ax.annotate('', xy=arrow['end'], xytext=arrow['start'],
                       arrowprops=dict(arrowstyle='->', color=arrow['color'], 
                                     lw=2.5, alpha=0.8))
        
        # æ·»åŠ é˜¶æ®µæ ‡è¯†
        ax.text(4.6, 7, 'Stage 1: Geometry Guidance', ha='center', fontsize=12, 
               fontweight='bold', color='darkblue',
               bbox=dict(boxstyle="round,pad=0.3", facecolor="lightsteelblue", alpha=0.7))
        
        ax.text(4.6, 1.5, 'Stage 2: Deformable Sampling', ha='center', fontsize=12, 
               fontweight='bold', color='darkmagenta',
               bbox=dict(boxstyle="round,pad=0.3", facecolor="thistle", alpha=0.7))
        
        # Add explanation text
        ax.text(0.5, 0.5, 
               'â€¢ Stage 1: 2D track points guide 3D features\n'
               'â€¢ Stage 2: Deformable sampling for enhancement',
               fontsize=9, verticalalignment='bottom',
               bbox=dict(boxstyle="round,pad=0.5", facecolor="wheat", alpha=0.8))
    
    def visualize_appearance_enhancement_comparison(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–å¤–è§‚å¢å¼ºæ•ˆæœå¯¹æ¯”"""
        ax.set_title('Appearance Feature Enhancement Comparison', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # è®¡ç®—ç‰¹å¾è´¨é‡æŒ‡æ ‡ï¼ˆä½¿ç”¨PCAé™ç»´å¯è§†åŒ–ï¼‰
        from sklearn.decomposition import PCA
        
        # å¯¹ç‰¹å¾è¿›è¡ŒPCAé™ç»´åˆ°2D
        pca = PCA(n_components=2)
        
        # åˆå¹¶æ‰€æœ‰ç‰¹å¾è¿›è¡Œç»Ÿä¸€PCA
        all_features = np.vstack([
            data.base_features,
            data.geometry_guided_features, 
            data.enhanced_features
        ])
        pca.fit(all_features)
        
        # åˆ†åˆ«å˜æ¢å„é˜¶æ®µç‰¹å¾
        base_2d = pca.transform(data.base_features)
        guided_2d = pca.transform(data.geometry_guided_features)
        enhanced_2d = pca.transform(data.enhanced_features)
        
        # ç»˜åˆ¶æ•£ç‚¹å›¾å¯¹æ¯”
        ax.scatter(base_2d[:, 0], base_2d[:, 1], 
                  c='lightcoral', s=60, alpha=0.7, label='Base Features', marker='o')
        ax.scatter(guided_2d[:, 0], guided_2d[:, 1], 
                  c='lightblue', s=60, alpha=0.7, label='Geometry-Guided Features', marker='s')
        ax.scatter(enhanced_2d[:, 0], enhanced_2d[:, 1], 
                  c='gold', s=80, alpha=0.8, label='Enhanced Appearance Features', marker='*')
        
        # ç»˜åˆ¶æ¼”åŒ–ç®­å¤´ï¼ˆæ˜¾ç¤ºç‰¹å¾å˜åŒ–è½¨è¿¹ï¼‰
        for i in range(min(8, data.n_gaussians)):  # åªæ˜¾ç¤ºéƒ¨åˆ†ä»¥é¿å…è¿‡äºæ‹¥æŒ¤
            # åŸºç¡€ -> å¼•å¯¼
            ax.annotate('', xy=guided_2d[i], xytext=base_2d[i],
                       arrowprops=dict(arrowstyle='->', color='steelblue', 
                                     alpha=0.5, lw=1.5))
            # å¼•å¯¼ -> å¢å¼º
            ax.annotate('', xy=enhanced_2d[i], xytext=guided_2d[i],
                       arrowprops=dict(arrowstyle='->', color='orange', 
                                     alpha=0.6, lw=2))
        
        ax.set_xlabel(f'Principal Component 1 (Explained Variance: {pca.explained_variance_ratio_[0]:.1%})')
        ax.set_ylabel(f'Principal Component 2 (Explained Variance: {pca.explained_variance_ratio_[1]:.1%})')
        ax.legend(loc='best', fontsize=10)
        ax.grid(True, alpha=0.3)
        
        # è®¡ç®—å¹¶æ˜¾ç¤ºæ”¹å–„ç»Ÿè®¡
        base_var = np.var(base_2d, axis=0).sum()
        guided_var = np.var(guided_2d, axis=0).sum()
        enhanced_var = np.var(enhanced_2d, axis=0).sum()
        
        improvement_1 = (guided_var - base_var) / base_var * 100
        improvement_2 = (enhanced_var - guided_var) / guided_var * 100
        
        ax.text(0.02, 0.98, 
               f'S1: {improvement_1:+.1f}%\n'
               f'S2: {improvement_2:+.1f}%\n'
               f'Total: {(enhanced_var-base_var)/base_var*100:+.1f}%',
               transform=ax.transAxes, fontsize=10, verticalalignment='top',
               bbox=dict(boxstyle="round,pad=0.3", facecolor="lightgreen", alpha=0.8))
    
    def visualize_performance_metrics_analysis(self, data: GTDCAVisualizationData, ax: plt.Axes):
        """å¯è§†åŒ–æ€§èƒ½æŒ‡æ ‡åˆ†æ"""
        ax.set_title('GTD-CA Performance Metrics Analysis', 
                    fontsize=14, fontweight='bold', pad=20)
        
        # å‡†å¤‡æ•°æ®
        metrics = data.performance_metrics
        metric_names = ['Feature Quality\nImprovement', 'Attention\nAlignment', 'Sampling\nEfficiency', 'Geometric\nConsistency']
        
        # è®¡ç®—æ¯ä¸ªæŒ‡æ ‡çš„ç»Ÿè®¡é‡
        means = []
        stds = []
        for key in ['feature_quality_improvement', 'attention_alignment_score', 
                   'sampling_efficiency', 'geometric_consistency']:
            values = metrics[key]
            if key == 'feature_quality_improvement':
                means.append(np.mean(values))
                stds.append(np.std(values))
            else:
                means.append(np.mean(values) * 100)  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
                stds.append(np.std(values) * 100)
        
        # ç»˜åˆ¶æŸ±çŠ¶å›¾
        x_pos = np.arange(len(metric_names))
        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4']
        
        bars = ax.bar(x_pos, means, yerr=stds, capsize=5, 
                     color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, mean, std) in enumerate(zip(bars, means, stds)):
            height = bar.get_height()
            if i == 0:  # ç‰¹å¾è´¨é‡æ”¹å–„ï¼ˆç™¾åˆ†æ¯”ï¼‰
                ax.text(bar.get_x() + bar.get_width()/2., height + std + 1,
                       f'{mean:.1f}%', ha='center', va='bottom', 
                       fontweight='bold', fontsize=10)
            else:  # å…¶ä»–æŒ‡æ ‡ï¼ˆåˆ†æ•°ï¼‰
                ax.text(bar.get_x() + bar.get_width()/2., height + std + 1,
                       f'{mean:.1f}', ha='center', va='bottom', 
                       fontweight='bold', fontsize=10)
        
        ax.set_ylabel('Performance Score')
        ax.set_xticks(x_pos)
        ax.set_xticklabels(metric_names, fontsize=11)
        ax.set_ylim(0, max(means) + max(stds) + 10)
        
        # æ·»åŠ ç½‘æ ¼
        ax.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ åŸºå‡†çº¿
        ax.axhline(y=80, color='red', linestyle='--', alpha=0.7, label='Target Baseline (80)')
        ax.legend(loc='upper right', fontsize=9)
        
        # æ·»åŠ æ”¹å–„æ€»ç»“
        overall_score = np.mean([means[1], means[2], means[3]])  # æ’é™¤ç‰¹å¾è´¨é‡æ”¹å–„
        ax.text(0.02, 0.98, 
               f'Overall Performance Score: {overall_score:.1f}/100\n'
               f'Feature Quality Improvement: {means[0]:.1f}%\n'
               f'Average of All Metrics: {np.mean(means[1:]):.1f}',
               transform=ax.transAxes, fontsize=10, verticalalignment='top',
               bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.8))
    
    def create_complete_visualization(self, data: GTDCAVisualizationData = None, 
                                    save_plots: bool = True) -> None:
        """åˆ›å»ºå®Œæ•´çš„GTD-CAå¯è§†åŒ–å›¾è¡¨"""
        if data is None:
            data = GTDCAVisualizationData()
        
        # åˆ›å»º2Ã—3ç½‘æ ¼å¸ƒå±€
        fig = plt.figure(figsize=(20, 14))
        gs = GridSpec(2, 3, figure=fig, hspace=0.35, wspace=0.25)
        
        # åˆ›å»ºå­å›¾
        ax1 = fig.add_subplot(gs[0, 0])  # å‡ ä½•å¼•å¯¼æœºåˆ¶
        ax2 = fig.add_subplot(gs[0, 1])  # å¯å˜å½¢é‡‡æ ·è¿‡ç¨‹
        ax3 = fig.add_subplot(gs[0, 2])  # äº¤å‰æ³¨æ„åŠ›æƒé‡
        ax4 = fig.add_subplot(gs[1, 0])  # ä¸¤é˜¶æ®µå¤„ç†æµç¨‹
        ax5 = fig.add_subplot(gs[1, 1])  # å¤–è§‚å¢å¼ºæ•ˆæœå¯¹æ¯”
        ax6 = fig.add_subplot(gs[1, 2])  # æ€§èƒ½æŒ‡æ ‡åˆ†æ
        
        # å¡«å……å„ä¸ªå­å›¾
        print("ğŸ¨ ç”Ÿæˆå‡ ä½•å¼•å¯¼æœºåˆ¶å¯è§†åŒ–...")
        self.visualize_geometry_guidance_mechanism(data, ax1)
        
        print("ğŸ¨ ç”Ÿæˆå¯å˜å½¢é‡‡æ ·è¿‡ç¨‹å¯è§†åŒ–...")
        self.visualize_deformable_sampling_process(data, ax2)
        
        print("ğŸ¨ ç”Ÿæˆäº¤å‰æ³¨æ„åŠ›æƒé‡åˆ†æ...")
        self.visualize_cross_attention_weights(data, ax3)
        
        print("ğŸ¨ ç”Ÿæˆä¸¤é˜¶æ®µå¤„ç†æµç¨‹å›¾...")
        self.visualize_two_stage_pipeline(data, ax4)
        
        print("ğŸ¨ ç”Ÿæˆå¤–è§‚å¢å¼ºæ•ˆæœå¯¹æ¯”...")
        self.visualize_appearance_enhancement_comparison(data, ax5)
        
        print("ğŸ¨ ç”Ÿæˆæ€§èƒ½æŒ‡æ ‡åˆ†æ...")
        self.visualize_performance_metrics_analysis(data, ax6)
        
        # æ·»åŠ æ€»æ ‡é¢˜
        fig.suptitle('GTD-CA Enhanced Appearance Modeling Visualization', 
                    fontsize=18, fontweight='bold', y=0.95)
        
        if save_plots:
            # ä¿å­˜ä¸»è¦å¯è§†åŒ–å›¾
            main_output = self.output_dir / "gtd_ca_enhanced_appearance_modeling.png"
            fig.savefig(main_output, dpi=300, bbox_inches='tight', 
                       facecolor='white', edgecolor='none')
            print(f"âœ… ä¸»è¦å¯è§†åŒ–å›¾å·²ä¿å­˜: {main_output}")
        
        return fig


def main():
    """Main function"""
    parser = argparse.ArgumentParser(description='GTD-CA Enhanced Appearance Modeling Visualization Tool')
    parser.add_argument('--model_path', type=str, default=None,
                       help='Training model path (e.g., output/your_model)')
    parser.add_argument('--ply_path', type=str, default=None,
                       help='Direct PLY file path')
    parser.add_argument('--iteration', type=int, default=30000,
                       help='Specify iteration number (default: 30000)')
    parser.add_argument('--output_dir', type=str, default='./visualization_outputs/gtdca_default',
                       help='Output directory path (will be created if not exists). Examples: "./visualization_outputs/flower_gtdca", "./visualization_outputs/chair_gtdca"')
    parser.add_argument('--use_synthetic', action='store_true',
                       help='Force use of synthetic data for demonstration')
    parser.add_argument('--max_gaussians', type=int, default=1000,
                       help='Maximum number of Gaussian primitives (memory optimization)')
    parser.add_argument('--sampling_method', type=str, default='smart', 
                       choices=['random', 'smart', 'spatial'],
                       help='Gaussian primitive sampling method')
    parser.add_argument('--n_gaussians', type=int, default=25,
                       help='Synthetic data: number of Gaussian primitives')
    parser.add_argument('--n_track_points', type=int, default=15,
                       help='Synthetic data: number of track points')
    parser.add_argument('--n_sample_points', type=int, default=8,
                       help='Synthetic data: number of sample points per primitive')
    parser.add_argument('--feature_dim', type=int, default=256,
                       help='Synthetic data: feature dimension')
    
    args = parser.parse_args()
    
    # æ™ºèƒ½è¾“å‡ºç›®å½•ï¼šå¦‚æœä½¿ç”¨é»˜è®¤å€¼ä¸”æä¾›äº†PLYè·¯å¾„ï¼Œåˆ™æ ¹æ®PLYæ–‡ä»¶ç”Ÿæˆç›®å½•å
    output_dir = args.output_dir
    if args.output_dir == "./visualization_outputs/gtdca_default" and args.ply_path:
        # ä»PLYè·¯å¾„æå–åœºæ™¯åç§°
        ply_path = Path(args.ply_path)
        # å°è¯•ä»è·¯å¾„ä¸­æå–åœºæ™¯åï¼ˆå¦‚flower, chairç­‰ï¼‰
        path_parts = ply_path.parts
        scene_name = None
        for part in path_parts:
            if part in ['flower', 'chair', 'lego', 'drums', 'ficus', 'hotdog', 'materials', 'mic', 'ship']:
                scene_name = part
                break
        
        if scene_name:
            output_dir = f"./visualization_outputs/gtdca_{scene_name}"
            print(f"ğŸ¯ æ™ºèƒ½è¾“å‡ºç›®å½•: {output_dir}")
        else:
            # å¦‚æœæ²¡æœ‰è¯†åˆ«åˆ°åœºæ™¯åï¼Œå°è¯•ä»è¿­ä»£æ•°æå–ä¿¡æ¯
            iteration_match = None
            for part in path_parts:
                if 'iteration_' in part:
                    iteration_match = part
                    break
            if iteration_match:
                output_dir = f"./visualization_outputs/gtdca_{iteration_match}"
                print(f"ğŸ¯ æ™ºèƒ½è¾“å‡ºç›®å½•: {output_dir}")
    
    print("ğŸš€ å¯åŠ¨GTD-CAå¢å¼ºå¤–è§‚å»ºæ¨¡å¯è§†åŒ–å™¨...")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = GTDCAEnhancedAppearanceVisualizer(output_dir)
    
    # ç”Ÿæˆæˆ–åŠ è½½æ•°æ®
    if args.use_synthetic or (not args.model_path and not args.ply_path):
        print(f"ğŸ“Š ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®: {args.n_gaussians}ä¸ªé«˜æ–¯åŸºå…ƒ, {args.n_track_points}ä¸ªè½¨è¿¹ç‚¹...")
        data = GTDCAVisualizationData(
            n_gaussians=args.n_gaussians,
            n_track_points=args.n_track_points,
            n_sample_points=args.n_sample_points,
            feature_dim=args.feature_dim,
            use_synthetic=True
        )
    else:
        print("ğŸ“‚ å°è¯•åŠ è½½çœŸå®æ¨¡å‹æ•°æ®...")
        data = GTDCAVisualizationData(
            model_path=args.model_path,
            ply_path=args.ply_path,
            iteration=args.iteration,
            n_gaussians=args.n_gaussians,
            n_track_points=args.n_track_points,
            n_sample_points=args.n_sample_points,
            feature_dim=args.feature_dim,
            use_synthetic=False,
            max_gaussians=args.max_gaussians,
            sampling_method=args.sampling_method
        )
    
    # åˆ›å»ºå®Œæ•´å¯è§†åŒ–
    print("ğŸ¨ ç”Ÿæˆå®Œæ•´å¯è§†åŒ–å›¾è¡¨...")
    fig = visualizer.create_complete_visualization(data, save_plots=True)
    
    print("âœ… GTD-CAå¢å¼ºå¤–è§‚å»ºæ¨¡å¯è§†åŒ–å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡ä¿¡æ¯
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"   - é«˜æ–¯åŸºå…ƒæ•°é‡: {data.n_gaussians}")
    print(f"   - è½¨è¿¹ç‚¹æ•°é‡: {len(data.track_points_2d)}")
    print(f"   - ç‰¹å¾ç»´åº¦: {data.feature_dim}")
    print(f"   - é‡‡æ ·ç‚¹æ•°é‡: {data.n_sample_points}")
    
    # æ˜¾ç¤ºå›¾è¡¨ï¼ˆå¦‚æœåœ¨äº¤äº’ç¯å¢ƒä¸­ï¼‰
    try:
        plt.show()
    except:
        print("ğŸ“ éäº¤äº’ç¯å¢ƒï¼Œè·³è¿‡å›¾è¡¨æ˜¾ç¤º")


if __name__ == "__main__":
    main()